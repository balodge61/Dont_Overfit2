{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category= DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "from sklearn import  metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression,Lasso , Ridge\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train.csv')\n",
    "test_df=pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "target_col = [\"target\"]\n",
    "id_dataset = [\"id\"]\n",
    "#numerical columns\n",
    "num_cols   = [x for x in train_df.columns if x not in target_col + id_dataset]\n",
    "\n",
    "#Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(train_df[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_data_og = train_df.copy()\n",
    "data = train_df.drop(columns = num_cols,axis = 1)\n",
    "data = data.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "data = data.drop(columns = ['id'],axis = 1)\n",
    "\n",
    "#test \n",
    "target_col = [\"target\"]\n",
    "id_dataset = [\"id\"]\n",
    "#numerical columns\n",
    "num_cols   = [x for x in test_df.columns if x not in target_col + id_dataset]\n",
    "\n",
    "#Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(test_df[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_test_og = test_df.copy()\n",
    "test = test_df.drop(columns = num_cols,axis = 1)\n",
    "test = test.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "test = test.drop(columns = ['id'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  33     0.373608\n",
      "        65     0.293846\n",
      "32      75     0.259315\n",
      "101     193    0.252825\n",
      "22      28     0.246062\n",
      "dtype: float64\n",
      "target    1.000000\n",
      "33        0.373608\n",
      "65        0.293846\n",
      "217       0.207215\n",
      "117       0.197496\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#### Check correlation and drop ####\n",
    "\n",
    "corr_matrix = pd.DataFrame(data)\n",
    "\n",
    "corr = corr_matrix.corr().abs()\n",
    "corr = (corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "                 .stack()\n",
    "                 .sort_values(ascending=False))\n",
    "print(corr.head(5))\n",
    "\n",
    "#### Also check correlation to target variable ####\n",
    "cor_t = pd.DataFrame(data).apply(lambda x: x.corr(data.target)).abs().sort_values(ascending=False)\n",
    "print(cor_t.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Def X and Y\n",
    "\n",
    "#data = data.sample(frac=1)\n",
    "\n",
    "x = data.drop('target', 1)\n",
    "y = data['target']\n",
    "\n",
    "seed = 12\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = .2, random_state=seed)\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "x_train_res, y_train_res = sm.fit_sample(x_train, y_train)\n",
    "\n",
    "#x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "0.62\n",
      "0.7857142857142857\n",
      "0.924\n",
      "0.9625\n",
      "pred:  [[0.44 0.56]\n",
      " [0.24 0.76]\n",
      " [0.44 0.56]\n",
      " ...\n",
      " [0.56 0.44]\n",
      " [0.36 0.64]\n",
      " [0.56 0.44]]\n",
      "cv scores:  [0.68 0.64 0.6  0.68 0.64 0.64 0.68 0.56 0.72 0.56]\n",
      "avg of the cv scores:  0.64\n",
      "stdev of the cv scores:  0.0506\n",
      "ROC_AUC is:  0.9836\n",
      "Sum of probabilites:  [ 8159.48 11590.52]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=seed)\n",
    "clf_rf.fit(x_train_res, y_train_res)\n",
    "\n",
    "print('Validation Results')\n",
    "print(clf_rf.score(x_val, y_val))\n",
    "print(recall_score(y_val, clf_rf.predict(x_val)))\n",
    "print(clf_rf.score(x, y))\n",
    "print(recall_score(y, clf_rf.predict(x)))\n",
    "\n",
    "pred = clf_rf.predict_proba(test)\n",
    "print('pred: ',pred)\n",
    "\n",
    "model_score = cross_val_score(clf_rf, x, y, cv=10, )\n",
    "print('cv scores: ',model_score)\n",
    "print('avg of the cv scores: ',model_score.mean().round(4))\n",
    "print('stdev of the cv scores: ',model_score.std().round(4))\n",
    "\n",
    "prediction = pd.DataFrame(clf_rf.predict_proba(x)).drop(columns = 0, axis = 1)\n",
    "print('ROC_AUC is: ',roc_auc_score(y, prediction).round(4))\n",
    "print('Sum of probabilites: ',sum(pred))\n",
    "#print(logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of  84 | elapsed:    3.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:    3.4s finished\n",
      "C:\\Users\\balod\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.8069269042627533\n",
      "Best Parameters: {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "pred:  [[0.50014807 0.49985193]\n",
      " [0.41717814 0.58282186]\n",
      " [0.27595924 0.72404076]\n",
      " ...\n",
      " [0.74214748 0.25785252]\n",
      " [0.08625468 0.91374532]\n",
      " [0.68912924 0.31087076]]\n",
      "cv scores:  [0.78571429 0.82142857 0.65384615 0.80769231 0.84615385 0.92307692\n",
      " 0.80769231 0.88461538 0.84615385 0.88461538]\n",
      "avg of the cv scores:  0.8261\n",
      "stdev of the cv scores:  0.07\n",
      "ROC_AUC is:  0.9827\n",
      "Sum of probabilites:  [ 9223.61832321 10526.38167679]\n"
     ]
    }
   ],
   "source": [
    "logreg=LogisticRegression(random_state=seed)\n",
    "param_grid={ 'class_weight': ['balanced', None],\n",
    "              'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "             'solver' : ['liblinear'],\n",
    "              'penalty':['l1','l2']\n",
    "           }\n",
    "grid=GridSearchCV(logreg, param_grid = param_grid , scoring = 'roc_auc', verbose = 1, n_jobs = -1)\n",
    "grid.fit(x,y)\n",
    "\n",
    "print(\"Best Score:\" + str(grid.best_score_))\n",
    "print(\"Best Parameters: \" + str(grid.best_params_))\n",
    "\n",
    "logreg = LogisticRegression(random_state = seed, \n",
    "                             C = .1, class_weight = 'balanced',\n",
    "                             penalty = 'l1', solver = 'liblinear')\n",
    "logreg.fit(x_train_res,y_train_res)\n",
    "pred = logreg.predict_proba(test)\n",
    "print('pred: ',pred)\n",
    "\n",
    "model_score = cross_val_score(logreg, x_train_res, y_train_res, cv=10, )\n",
    "print('cv scores: ',model_score)\n",
    "print('avg of the cv scores: ',model_score.mean().round(4))\n",
    "print('stdev of the cv scores: ',model_score.std().round(4))\n",
    "\n",
    "prediction = pd.DataFrame(logreg.predict_proba(x_train_res)).drop(columns = 0, axis = 1)\n",
    "print('ROC_AUC is: ',roc_auc_score(y_train_res, prediction).round(4))\n",
    "print('Sum of probabilites: ',sum(pred))\n",
    "#print(logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearSVC().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Score:0.6989196366177498\n",
      "Best Parameters: {'C': 0.001}\n",
      "pred:  [1. 0. 0. ... 1. 1. 0.]\n",
      "cv scores:  [0.76 0.6  0.6  0.64 0.8  0.56 0.64 0.64 0.68 0.68]\n",
      "avg of the cv scores:  0.66\n",
      "stdev of the cv scores:  0.0699\n",
      "ROC_AUC is:  0.9844\n",
      "Sum of probabilites:  12378.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "C:\\Users\\balod\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC(random_state=seed)\n",
    "param_grid={'C':[0.001, 0.01, 0.1, 1, 10],\n",
    "            #'penalty':['l1','l2']\n",
    "           }\n",
    "grid=GridSearchCV(model, param_grid = param_grid , scoring = 'roc_auc', verbose = 1, n_jobs = -1)\n",
    "grid.fit(x,y)\n",
    "\n",
    "print(\"Best Score:\" + str(grid.best_score_))\n",
    "print(\"Best Parameters: \" + str(grid.best_params_))\n",
    "\n",
    "model = LinearSVC(random_state = seed, C = .001,)\n",
    "model.fit(x,y)\n",
    "pred = model.predict(test)\n",
    "print('pred: ',pred)\n",
    "\n",
    "model_score = cross_val_score(model, x, y, cv=10, )\n",
    "print('cv scores: ',model_score)\n",
    "print('avg of the cv scores: ',model_score.mean().round(4))\n",
    "print('stdev of the cv scores: ',model_score.std().round(4))\n",
    "\n",
    "prediction = pd.DataFrame(model.predict(x))\n",
    "print('ROC_AUC is: ',roc_auc_score(y, prediction).round(4))\n",
    "print('Sum of probabilites: ',sum(pred))\n",
    "#print(logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = logreg\n",
    "\n",
    "submission = pd.read_csv('submission.csv')\n",
    "final_test = test\n",
    "submission['target'] = selector.predict_proba(final_test)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
